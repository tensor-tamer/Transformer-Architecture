{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftm74ltjfSbn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from stl import mesh\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from scipy.spatial import KDTree\n",
        "\n",
        "class ComplexSTLTransformer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, num_points=1024, normalize=True, feature_type='geometry'):\n",
        "        \"\"\"\n",
        "        Initialize the ComplexSTLTransformer.\n",
        "\n",
        "        Parameters:\n",
        "        - num_points (int): The number of points to sample from the mesh surface.\n",
        "        - normalize (bool): Whether to normalize the mesh.\n",
        "        - feature_type (str): The type of feature to extract ('geometry').\n",
        "        \"\"\"\n",
        "        self.num_points = num_points\n",
        "        self.normalize = normalize\n",
        "        self.feature_type = feature_type\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"\n",
        "        Transform the STL files into a numerical feature matrix (point cloud).\n",
        "\n",
        "        Parameters:\n",
        "        - X (list): A list of paths to STL files.\n",
        "\n",
        "        Returns:\n",
        "        - np.ndarray: A 3D array where each entry is a point cloud representation of an STL file.\n",
        "        \"\"\"\n",
        "        point_clouds = []\n",
        "\n",
        "        for stl_file_path in X:\n",
        "            # Load the STL file\n",
        "            dental_mesh = mesh.Mesh.from_file(stl_file_path)\n",
        "            vertices = dental_mesh.vectors.reshape(-1, 3)  # (N, 3) array of vertices\n",
        "\n",
        "            # Normalize the mesh if required\n",
        "            if self.normalize:\n",
        "                vertices = self._normalize_mesh(vertices)\n",
        "\n",
        "            # Sample points from the mesh surface\n",
        "            point_cloud = self._sample_points(vertices)\n",
        "\n",
        "            # Extract additional features if needed\n",
        "            if self.feature_type == 'geometry':\n",
        "                point_cloud = self._augment_with_normals(point_cloud)\n",
        "\n",
        "            point_clouds.append(point_cloud)\n",
        "\n",
        "        return np.array(point_clouds)\n",
        "\n",
        "    def _normalize_mesh(self, vertices):\n",
        "        \"\"\"\n",
        "        Normalize the mesh to be centered and scaled to unit size.\n",
        "\n",
        "        Parameters:\n",
        "        - vertices (np.ndarray): Array of vertices.\n",
        "\n",
        "        Returns:\n",
        "        - np.ndarray: Normalized vertices.\n",
        "        \"\"\"\n",
        "        # Center the mesh\n",
        "        center = np.mean(vertices, axis=0)\n",
        "        vertices -= center\n",
        "\n",
        "        # Scale to unit size\n",
        "        max_extent = np.max(np.linalg.norm(vertices, axis=1))\n",
        "        vertices /= max_extent\n",
        "\n",
        "        return vertices\n",
        "\n",
        "    def _sample_points(self, vertices):\n",
        "        \"\"\"\n",
        "        Sample points uniformly across the mesh surface.\n",
        "\n",
        "        Parameters:\n",
        "        - vertices (np.ndarray): Array of vertices.\n",
        "\n",
        "        Returns:\n",
        "        - np.ndarray: Sampled point cloud.\n",
        "        \"\"\"\n",
        "        num_vertices = len(vertices)\n",
        "        sampled_indices = np.random.choice(num_vertices, self.num_points, replace=True)\n",
        "        point_cloud = vertices[sampled_indices]\n",
        "\n",
        "        return point_cloud\n",
        "\n",
        "    def _augment_with_normals(self, point_cloud):\n",
        "        \"\"\"\n",
        "        Augment the point cloud with surface normals.\n",
        "\n",
        "        Parameters:\n",
        "        - point_cloud (np.ndarray): Array of sampled points.\n",
        "\n",
        "        Returns:\n",
        "        - np.ndarray: Point cloud with augmented features.\n",
        "        \"\"\"\n",
        "        # Construct KDTree for nearest neighbors\n",
        "        kdtree = KDTree(point_cloud)\n",
        "        normals = np.zeros_like(point_cloud)\n",
        "\n",
        "        # Estimate normals by local neighborhood\n",
        "        for i, point in enumerate(point_cloud):\n",
        "            distances, indices = kdtree.query(point, k=10)\n",
        "            neighbors = point_cloud[indices]\n",
        "            centroid = np.mean(neighbors, axis=0)\n",
        "            cov_matrix = np.cov((neighbors - centroid).T)\n",
        "            eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
        "            normal = eigenvectors[:, np.argmin(eigenvalues)]\n",
        "            normals[i] = normal\n",
        "\n",
        "        # Concatenate point coordinates with normals\n",
        "        point_cloud_with_normals = np.hstack((point_cloud, normals))\n",
        "\n",
        "        return point_cloud_with_normals"
      ]
    }
  ]
}